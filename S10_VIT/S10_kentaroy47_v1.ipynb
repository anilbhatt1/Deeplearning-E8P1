{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HowoVBNLCBfS",
        "outputId": "46b2aaee-4a74-40d7-c42a-6197596f72e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thu Mar 16 12:44:18 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.85.12    Driver Version: 525.85.12    CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   61C    P0    27W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install einops"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EVaTeJd-wg5H",
        "outputId": "ab8987c9-284f-4c56-f7f8-6f404a58368e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting einops\n",
            "  Downloading einops-0.6.0-py3-none-any.whl (41 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.6/41.6 KB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: einops\n",
            "Successfully installed einops-0.6.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from collections import defaultdict\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torchvision import datasets, transforms\n",
        "import torchvision\n",
        "from einops import rearrange, repeat\n",
        "from einops.layers.torch import Rearrange\n",
        "from tqdm import tqdm\n",
        "from tqdm.notebook import trange, tqdm"
      ],
      "metadata": {
        "id": "VgvmFNNCCCgl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W4OMBJ6mxsjB"
      },
      "outputs": [],
      "source": [
        "DATA_DIR='./data'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WZejmg6qxsjB",
        "outputId": "5ac14e5b-df13-4262-9499-44f5613a71dc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "device: cuda\n"
          ]
        }
      ],
      "source": [
        "DEVICE = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "print(\"device:\", DEVICE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "171uPlqXxsjD"
      },
      "outputs": [],
      "source": [
        "# helpers\n",
        "def pair(t):\n",
        "    return t if isinstance(t, tuple) else (t, t)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "39-F1AytxsjD"
      },
      "outputs": [],
      "source": [
        "class PreNorm(nn.Module):\n",
        "    def __init__(self, dim, fn):\n",
        "        super().__init__()\n",
        "        self.norm = nn.LayerNorm(dim)\n",
        "        self.fn = fn\n",
        "    def forward(self, x, **kwargs):\n",
        "        return self.fn(self.norm(x), **kwargs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bGt11ksHxsjE"
      },
      "outputs": [],
      "source": [
        "class FeedForward(nn.Module):\n",
        "    def __init__(self, dim, hidden_dim, dropout = 0.):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(dim, hidden_dim),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(hidden_dim, dim),\n",
        "            nn.Dropout(dropout)\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        out = self.net(x)\n",
        "        print(f'    FeedForward out.shape - {out.shape}')\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qaslNgohxsjG"
      },
      "outputs": [],
      "source": [
        "class Attention(nn.Module):\n",
        "    def __init__(self, dim, heads = 8, dim_head = 64, dropout = 0.):\n",
        "        super().__init__()\n",
        "        inner_dim = dim_head *  heads\n",
        "        project_out = not (heads == 1 and dim_head == dim)\n",
        "\n",
        "        self.heads = heads\n",
        "        self.scale = dim_head ** -0.5\n",
        "\n",
        "        self.attend = nn.Softmax(dim = -1)\n",
        "        self.to_qkv = nn.Linear(dim, inner_dim * 3, bias = False)\n",
        "\n",
        "        self.to_out = nn.Sequential(\n",
        "            nn.Linear(inner_dim, dim),\n",
        "            nn.Dropout(dropout)\n",
        "        ) if project_out else nn.Identity()\n",
        "\n",
        "    def forward(self, x):\n",
        "        qkv = self.to_qkv(x).chunk(3, dim = -1)\n",
        "        print(f'    Attention qkv.shape: {qkv[0].shape} , {qkv[1].shape} , {qkv[2].shape} ')\n",
        "        q, k, v = map(lambda t: rearrange(t, 'b n (h d) -> b h n d', h = self.heads), qkv)\n",
        "        print(f'    Attention q, k, v after rearranging qkv: {q.shape} , {k.shape} , {v.shape}')\n",
        "\n",
        "        dots = torch.matmul(q, k.transpose(-1, -2)) * self.scale\n",
        "        print(f'    Attention dots.shape after matmul q and k.transpose: {dots.shape}')\n",
        "\n",
        "        attn = self.attend(dots)\n",
        "\n",
        "        out = torch.matmul(attn, v)\n",
        "        print(f'    Attention out.shape after matmul attn and v: {out.shape}')\n",
        "        out = rearrange(out, 'b h n d -> b n (h d)')\n",
        "        print(f'    Attention out.shape after rearrange: {out.shape}')\n",
        "        return self.to_out(out)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VOLfx7w9xsjH"
      },
      "outputs": [],
      "source": [
        "class Transformer(nn.Module):\n",
        "    def __init__(self, dim, depth, heads, dim_head, mlp_dim, dropout = 0.):\n",
        "        super().__init__()\n",
        "        self.layers = nn.ModuleList([])\n",
        "        for _ in range(depth):\n",
        "            self.layers.append(nn.ModuleList([\n",
        "                PreNorm(dim, Attention(dim, heads = heads, dim_head = dim_head, dropout = dropout)),\n",
        "                PreNorm(dim, FeedForward(dim, mlp_dim, dropout = dropout))\n",
        "            ]))\n",
        "    def forward(self, x):\n",
        "        cnt = 1\n",
        "        for attn, ff in self.layers:\n",
        "            print(f' **Transformer Layer - {cnt}**')\n",
        "            print(f'    x.shape before attn(x) + x: {x.shape}')\n",
        "            x = attn(x) + x\n",
        "            print(f'    x.shape after attn(x) + x : {x.shape}')\n",
        "            x = ff(x) + x\n",
        "            print(f'    x.shape after ff(x) + x   : {x.shape}')\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DcKbq_4OxsjH"
      },
      "outputs": [],
      "source": [
        "class ViT(nn.Module):\n",
        "    def __init__(self, *, image_size, patch_size, num_classes, dim, depth, heads, mlp_dim, pool = 'cls', channels = 3, dim_head = 64, dropout = 0., emb_dropout = 0.):\n",
        "        super().__init__()\n",
        "        image_height, image_width = pair(image_size)\n",
        "        print(f' vit-init image_size, image_height, image_width : {image_size}, {image_height}, {image_width}')\n",
        "        patch_height, patch_width = pair(patch_size)\n",
        "        print(f' vit-init patch_size, patch_height, patch_width : {patch_size}, {patch_height}, {patch_width}')\n",
        "\n",
        "        assert image_height % patch_height == 0 and image_width % patch_width == 0, 'Image dimensions must be divisible by the patch size.'\n",
        "\n",
        "        num_patches = (image_height // patch_height) * (image_width // patch_width)\n",
        "        print(f' vit-init num_patches : {num_patches}')\n",
        "        patch_dim = channels * patch_height * patch_width\n",
        "        print(f' vit-init patch_dim, channels : {patch_dim}, {channels}')\n",
        "        assert pool in {'cls', 'mean'}, 'pool type must be either cls (cls token) or mean (mean pooling)'\n",
        "        print(f' vit-init num_classes, dim, depth, heads, mlp_dim, dim_head : {num_classes}, {dim}, {depth}, {heads}, {mlp_dim}, {dim_head}')\n",
        "\n",
        "        self.to_patch_embedding = nn.Sequential(\n",
        "            Rearrange('b c (h p1) (w p2) -> b (h w) (p1 p2 c)', p1 = patch_height, p2 = patch_width),\n",
        "            nn.Linear(patch_dim, dim),\n",
        "        )\n",
        "\n",
        "        self.pos_embedding = nn.Parameter(torch.randn(1, num_patches + 1, dim))\n",
        "        self.cls_token = nn.Parameter(torch.randn(1, 1, dim))\n",
        "        self.dropout = nn.Dropout(emb_dropout)\n",
        "\n",
        "        self.transformer = Transformer(dim, depth, heads, dim_head, mlp_dim, dropout)\n",
        "\n",
        "        self.pool = pool\n",
        "        self.to_latent = nn.Identity()\n",
        "\n",
        "        self.mlp_head = nn.Sequential(\n",
        "            nn.LayerNorm(dim),\n",
        "            nn.Linear(dim, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, img):\n",
        "        print(f' vit-fwd img.size : {img.shape}')\n",
        "        x = self.to_patch_embedding(img)\n",
        "        print(f' vit-fwd self.to_patch_embedding.size : {x.shape}')\n",
        "        b, n, _ = x.shape\n",
        "        print(f' vit-fwd b, n, _ : {x.shape}')\n",
        "\n",
        "        cls_tokens = repeat(self.cls_token, '() n d -> b n d', b = b)\n",
        "        print(f' vit-fwd self.cls_token.shape : {self.cls_token.shape} , cls_tokens.shape : {cls_tokens.shape}')\n",
        "        x = torch.cat((cls_tokens, x), dim=1)\n",
        "        print(f' vit-fwd After concatenating cls_tokens with x ->  x.shape : {x.shape}')\n",
        "        x += self.pos_embedding[:, :(n + 1)]\n",
        "        print(f' vit-fwd self.pos_embedding.shape : {self.pos_embedding.shape},n : {n},  self.pos_embedding[:, :(n + 1)] : {self.pos_embedding[:, :(n + 1)].shape}')\n",
        "        print(f' vit-fwd After adding self.pos_embedding with x ->  x.shape : {x.shape}')\n",
        "        x = self.dropout(x)\n",
        "\n",
        "        x = self.transformer(x)\n",
        "        print(f' vit-fwd x.shape after transformer: {x.shape}')\n",
        "\n",
        "        x = x.mean(dim = 1) if self.pool == 'mean' else x[:, 0]\n",
        "        print(f' vit-fwd x.shape after mean: {x.shape}, self.pool : {self.pool}')\n",
        "\n",
        "        x = self.to_latent(x)\n",
        "        print(f' vit-fwd x.shape after self.to_latent(x): {x.shape}')\n",
        "        out = self.mlp_head(x)\n",
        "        print(f' vit-fwd out.shape after self.mlp_head(x): {out.shape}')\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = ViT(image_size=32,patch_size= 4,num_classes=10,\n",
        "            dim=512,depth=6,heads=8,mlp_dim=512,\n",
        "            dropout=0.1,emb_dropout=0.1)"
      ],
      "metadata": {
        "id": "VhRKwHixy0Bt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7a611d87-e361-41f0-fc64-4d6cdaf915b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " vit-init image_size, image_height, image_width : 32, 32, 32\n",
            " vit-init patch_size, patch_height, patch_width : 4, 4, 4\n",
            " vit-init num_patches : 64\n",
            " vit-init patch_dim, channels : 48, 3\n",
            " vit-init num_classes, dim, depth, heads, mlp_dim, dim_head : 10, 512, 6, 8, 512, 64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "s1 = torch.randn(1, 1, 512)\n",
        "s2 = repeat(s1, '() n d -> b n d', b = 32)\n",
        "# 1, 1, 512 -> 32, 1, 512\n",
        "s2.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6kjK0yGgEZMK",
        "outputId": "a20af027-80b9-4e6e-a6ca-d3e13137d1dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([32, 1, 512])"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mu4DG-twxsjJ",
        "outputId": "5b5b1d9a-b8ba-4fb3-d3ca-36b0b26ff9c3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ViT(\n",
              "  (to_patch_embedding): Sequential(\n",
              "    (0): Rearrange('b c (h p1) (w p2) -> b (h w) (p1 p2 c)', p1=4, p2=4)\n",
              "    (1): Linear(in_features=48, out_features=512, bias=True)\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (transformer): Transformer(\n",
              "    (layers): ModuleList(\n",
              "      (0): ModuleList(\n",
              "        (0): PreNorm(\n",
              "          (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "          (fn): Attention(\n",
              "            (attend): Softmax(dim=-1)\n",
              "            (to_qkv): Linear(in_features=512, out_features=1536, bias=False)\n",
              "            (to_out): Sequential(\n",
              "              (0): Linear(in_features=512, out_features=512, bias=True)\n",
              "              (1): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (1): PreNorm(\n",
              "          (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "          (fn): FeedForward(\n",
              "            (net): Sequential(\n",
              "              (0): Linear(in_features=512, out_features=512, bias=True)\n",
              "              (1): GELU(approximate='none')\n",
              "              (2): Dropout(p=0.1, inplace=False)\n",
              "              (3): Linear(in_features=512, out_features=512, bias=True)\n",
              "              (4): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (1): ModuleList(\n",
              "        (0): PreNorm(\n",
              "          (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "          (fn): Attention(\n",
              "            (attend): Softmax(dim=-1)\n",
              "            (to_qkv): Linear(in_features=512, out_features=1536, bias=False)\n",
              "            (to_out): Sequential(\n",
              "              (0): Linear(in_features=512, out_features=512, bias=True)\n",
              "              (1): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (1): PreNorm(\n",
              "          (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "          (fn): FeedForward(\n",
              "            (net): Sequential(\n",
              "              (0): Linear(in_features=512, out_features=512, bias=True)\n",
              "              (1): GELU(approximate='none')\n",
              "              (2): Dropout(p=0.1, inplace=False)\n",
              "              (3): Linear(in_features=512, out_features=512, bias=True)\n",
              "              (4): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (2): ModuleList(\n",
              "        (0): PreNorm(\n",
              "          (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "          (fn): Attention(\n",
              "            (attend): Softmax(dim=-1)\n",
              "            (to_qkv): Linear(in_features=512, out_features=1536, bias=False)\n",
              "            (to_out): Sequential(\n",
              "              (0): Linear(in_features=512, out_features=512, bias=True)\n",
              "              (1): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (1): PreNorm(\n",
              "          (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "          (fn): FeedForward(\n",
              "            (net): Sequential(\n",
              "              (0): Linear(in_features=512, out_features=512, bias=True)\n",
              "              (1): GELU(approximate='none')\n",
              "              (2): Dropout(p=0.1, inplace=False)\n",
              "              (3): Linear(in_features=512, out_features=512, bias=True)\n",
              "              (4): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (3): ModuleList(\n",
              "        (0): PreNorm(\n",
              "          (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "          (fn): Attention(\n",
              "            (attend): Softmax(dim=-1)\n",
              "            (to_qkv): Linear(in_features=512, out_features=1536, bias=False)\n",
              "            (to_out): Sequential(\n",
              "              (0): Linear(in_features=512, out_features=512, bias=True)\n",
              "              (1): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (1): PreNorm(\n",
              "          (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "          (fn): FeedForward(\n",
              "            (net): Sequential(\n",
              "              (0): Linear(in_features=512, out_features=512, bias=True)\n",
              "              (1): GELU(approximate='none')\n",
              "              (2): Dropout(p=0.1, inplace=False)\n",
              "              (3): Linear(in_features=512, out_features=512, bias=True)\n",
              "              (4): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (4): ModuleList(\n",
              "        (0): PreNorm(\n",
              "          (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "          (fn): Attention(\n",
              "            (attend): Softmax(dim=-1)\n",
              "            (to_qkv): Linear(in_features=512, out_features=1536, bias=False)\n",
              "            (to_out): Sequential(\n",
              "              (0): Linear(in_features=512, out_features=512, bias=True)\n",
              "              (1): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (1): PreNorm(\n",
              "          (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "          (fn): FeedForward(\n",
              "            (net): Sequential(\n",
              "              (0): Linear(in_features=512, out_features=512, bias=True)\n",
              "              (1): GELU(approximate='none')\n",
              "              (2): Dropout(p=0.1, inplace=False)\n",
              "              (3): Linear(in_features=512, out_features=512, bias=True)\n",
              "              (4): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (5): ModuleList(\n",
              "        (0): PreNorm(\n",
              "          (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "          (fn): Attention(\n",
              "            (attend): Softmax(dim=-1)\n",
              "            (to_qkv): Linear(in_features=512, out_features=1536, bias=False)\n",
              "            (to_out): Sequential(\n",
              "              (0): Linear(in_features=512, out_features=512, bias=True)\n",
              "              (1): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (1): PreNorm(\n",
              "          (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "          (fn): FeedForward(\n",
              "            (net): Sequential(\n",
              "              (0): Linear(in_features=512, out_features=512, bias=True)\n",
              "              (1): GELU(approximate='none')\n",
              "              (2): Dropout(p=0.1, inplace=False)\n",
              "              (3): Linear(in_features=512, out_features=512, bias=True)\n",
              "              (4): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (to_latent): Identity()\n",
              "  (mlp_head): Sequential(\n",
              "    (0): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "    (1): Linear(in_features=512, out_features=10, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "model.to(DEVICE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cFntUhVVxsjK",
        "outputId": "436af434-27ae-48a4-cc32-749689768cc2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of parameters: 9,523,722\n"
          ]
        }
      ],
      "source": [
        "print(\"Number of parameters: {:,}\".format(sum(p.numel() for p in model.parameters())))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchsummary\n",
        "from torchsummary import summary\n",
        "summary(model, input_size=(3, 32, 32))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qhj52m4k8wJs",
        "outputId": "4c7a53c7-c0eb-4093-b003-26e1000acd34"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torchsummary in /usr/local/lib/python3.9/dist-packages (1.5.1)\n",
            " vit-fwd img.size : torch.Size([2, 3, 32, 32])\n",
            " vit-fwd self.to_patch_embedding.size : torch.Size([2, 64, 512])\n",
            " vit-fwd b, n, _ : torch.Size([2, 64, 512])\n",
            " vit-fwd self.cls_token.shape : torch.Size([1, 1, 512]) , cls_tokens.shape : torch.Size([2, 1, 512])\n",
            " vit-fwd After concatenating cls_tokens with x ->  x.shape : torch.Size([2, 65, 512])\n",
            " vit-fwd self.pos_embedding.shape : torch.Size([1, 65, 512]),n : 64,  self.pos_embedding[:, :(n + 1)] : torch.Size([1, 65, 512])\n",
            " vit-fwd After adding self.pos_embedding with x ->  x.shape : torch.Size([2, 65, 512])\n",
            " **Transformer Layer - 1**\n",
            "    x.shape before attn(x) + x: torch.Size([2, 65, 512])\n",
            "    Attention qkv.shape: torch.Size([2, 65, 512]) , torch.Size([2, 65, 512]) , torch.Size([2, 65, 512]) \n",
            "    Attention q, k, v after rearranging qkv: torch.Size([2, 8, 65, 64]) , torch.Size([2, 8, 65, 64]) , torch.Size([2, 8, 65, 64])\n",
            "    Attention dots.shape after matmul q and k.transpose: torch.Size([2, 8, 65, 65])\n",
            "    Attention out.shape after matmul attn and v: torch.Size([2, 8, 65, 64])\n",
            "    Attention out.shape after rearrange: torch.Size([2, 65, 512])\n",
            "    x.shape after attn(x) + x : torch.Size([2, 65, 512])\n",
            "    FeedForward out.shape - torch.Size([2, 65, 512])\n",
            "    x.shape after ff(x) + x   : torch.Size([2, 65, 512])\n",
            " **Transformer Layer - 1**\n",
            "    x.shape before attn(x) + x: torch.Size([2, 65, 512])\n",
            "    Attention qkv.shape: torch.Size([2, 65, 512]) , torch.Size([2, 65, 512]) , torch.Size([2, 65, 512]) \n",
            "    Attention q, k, v after rearranging qkv: torch.Size([2, 8, 65, 64]) , torch.Size([2, 8, 65, 64]) , torch.Size([2, 8, 65, 64])\n",
            "    Attention dots.shape after matmul q and k.transpose: torch.Size([2, 8, 65, 65])\n",
            "    Attention out.shape after matmul attn and v: torch.Size([2, 8, 65, 64])\n",
            "    Attention out.shape after rearrange: torch.Size([2, 65, 512])\n",
            "    x.shape after attn(x) + x : torch.Size([2, 65, 512])\n",
            "    FeedForward out.shape - torch.Size([2, 65, 512])\n",
            "    x.shape after ff(x) + x   : torch.Size([2, 65, 512])\n",
            " **Transformer Layer - 1**\n",
            "    x.shape before attn(x) + x: torch.Size([2, 65, 512])\n",
            "    Attention qkv.shape: torch.Size([2, 65, 512]) , torch.Size([2, 65, 512]) , torch.Size([2, 65, 512]) \n",
            "    Attention q, k, v after rearranging qkv: torch.Size([2, 8, 65, 64]) , torch.Size([2, 8, 65, 64]) , torch.Size([2, 8, 65, 64])\n",
            "    Attention dots.shape after matmul q and k.transpose: torch.Size([2, 8, 65, 65])\n",
            "    Attention out.shape after matmul attn and v: torch.Size([2, 8, 65, 64])\n",
            "    Attention out.shape after rearrange: torch.Size([2, 65, 512])\n",
            "    x.shape after attn(x) + x : torch.Size([2, 65, 512])\n",
            "    FeedForward out.shape - torch.Size([2, 65, 512])\n",
            "    x.shape after ff(x) + x   : torch.Size([2, 65, 512])\n",
            " **Transformer Layer - 1**\n",
            "    x.shape before attn(x) + x: torch.Size([2, 65, 512])\n",
            "    Attention qkv.shape: torch.Size([2, 65, 512]) , torch.Size([2, 65, 512]) , torch.Size([2, 65, 512]) \n",
            "    Attention q, k, v after rearranging qkv: torch.Size([2, 8, 65, 64]) , torch.Size([2, 8, 65, 64]) , torch.Size([2, 8, 65, 64])\n",
            "    Attention dots.shape after matmul q and k.transpose: torch.Size([2, 8, 65, 65])\n",
            "    Attention out.shape after matmul attn and v: torch.Size([2, 8, 65, 64])\n",
            "    Attention out.shape after rearrange: torch.Size([2, 65, 512])\n",
            "    x.shape after attn(x) + x : torch.Size([2, 65, 512])\n",
            "    FeedForward out.shape - torch.Size([2, 65, 512])\n",
            "    x.shape after ff(x) + x   : torch.Size([2, 65, 512])\n",
            " **Transformer Layer - 1**\n",
            "    x.shape before attn(x) + x: torch.Size([2, 65, 512])\n",
            "    Attention qkv.shape: torch.Size([2, 65, 512]) , torch.Size([2, 65, 512]) , torch.Size([2, 65, 512]) \n",
            "    Attention q, k, v after rearranging qkv: torch.Size([2, 8, 65, 64]) , torch.Size([2, 8, 65, 64]) , torch.Size([2, 8, 65, 64])\n",
            "    Attention dots.shape after matmul q and k.transpose: torch.Size([2, 8, 65, 65])\n",
            "    Attention out.shape after matmul attn and v: torch.Size([2, 8, 65, 64])\n",
            "    Attention out.shape after rearrange: torch.Size([2, 65, 512])\n",
            "    x.shape after attn(x) + x : torch.Size([2, 65, 512])\n",
            "    FeedForward out.shape - torch.Size([2, 65, 512])\n",
            "    x.shape after ff(x) + x   : torch.Size([2, 65, 512])\n",
            " **Transformer Layer - 1**\n",
            "    x.shape before attn(x) + x: torch.Size([2, 65, 512])\n",
            "    Attention qkv.shape: torch.Size([2, 65, 512]) , torch.Size([2, 65, 512]) , torch.Size([2, 65, 512]) \n",
            "    Attention q, k, v after rearranging qkv: torch.Size([2, 8, 65, 64]) , torch.Size([2, 8, 65, 64]) , torch.Size([2, 8, 65, 64])\n",
            "    Attention dots.shape after matmul q and k.transpose: torch.Size([2, 8, 65, 65])\n",
            "    Attention out.shape after matmul attn and v: torch.Size([2, 8, 65, 64])\n",
            "    Attention out.shape after rearrange: torch.Size([2, 65, 512])\n",
            "    x.shape after attn(x) + x : torch.Size([2, 65, 512])\n",
            "    FeedForward out.shape - torch.Size([2, 65, 512])\n",
            "    x.shape after ff(x) + x   : torch.Size([2, 65, 512])\n",
            " vit-fwd x.shape after transformer: torch.Size([2, 65, 512])\n",
            " vit-fwd x.shape after mean: torch.Size([2, 512]), self.pool : cls\n",
            " vit-fwd x.shape after self.to_latent(x): torch.Size([2, 512])\n",
            " vit-fwd out.shape after self.mlp_head(x): torch.Size([2, 10])\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "         Rearrange-1               [-1, 64, 48]               0\n",
            "            Linear-2              [-1, 64, 512]          25,088\n",
            "           Dropout-3              [-1, 65, 512]               0\n",
            "         LayerNorm-4              [-1, 65, 512]           1,024\n",
            "            Linear-5             [-1, 65, 1536]         786,432\n",
            "           Softmax-6            [-1, 8, 65, 65]               0\n",
            "            Linear-7              [-1, 65, 512]         262,656\n",
            "           Dropout-8              [-1, 65, 512]               0\n",
            "         Attention-9              [-1, 65, 512]               0\n",
            "          PreNorm-10              [-1, 65, 512]               0\n",
            "        LayerNorm-11              [-1, 65, 512]           1,024\n",
            "           Linear-12              [-1, 65, 512]         262,656\n",
            "             GELU-13              [-1, 65, 512]               0\n",
            "          Dropout-14              [-1, 65, 512]               0\n",
            "           Linear-15              [-1, 65, 512]         262,656\n",
            "          Dropout-16              [-1, 65, 512]               0\n",
            "      FeedForward-17              [-1, 65, 512]               0\n",
            "          PreNorm-18              [-1, 65, 512]               0\n",
            "        LayerNorm-19              [-1, 65, 512]           1,024\n",
            "           Linear-20             [-1, 65, 1536]         786,432\n",
            "          Softmax-21            [-1, 8, 65, 65]               0\n",
            "           Linear-22              [-1, 65, 512]         262,656\n",
            "          Dropout-23              [-1, 65, 512]               0\n",
            "        Attention-24              [-1, 65, 512]               0\n",
            "          PreNorm-25              [-1, 65, 512]               0\n",
            "        LayerNorm-26              [-1, 65, 512]           1,024\n",
            "           Linear-27              [-1, 65, 512]         262,656\n",
            "             GELU-28              [-1, 65, 512]               0\n",
            "          Dropout-29              [-1, 65, 512]               0\n",
            "           Linear-30              [-1, 65, 512]         262,656\n",
            "          Dropout-31              [-1, 65, 512]               0\n",
            "      FeedForward-32              [-1, 65, 512]               0\n",
            "          PreNorm-33              [-1, 65, 512]               0\n",
            "        LayerNorm-34              [-1, 65, 512]           1,024\n",
            "           Linear-35             [-1, 65, 1536]         786,432\n",
            "          Softmax-36            [-1, 8, 65, 65]               0\n",
            "           Linear-37              [-1, 65, 512]         262,656\n",
            "          Dropout-38              [-1, 65, 512]               0\n",
            "        Attention-39              [-1, 65, 512]               0\n",
            "          PreNorm-40              [-1, 65, 512]               0\n",
            "        LayerNorm-41              [-1, 65, 512]           1,024\n",
            "           Linear-42              [-1, 65, 512]         262,656\n",
            "             GELU-43              [-1, 65, 512]               0\n",
            "          Dropout-44              [-1, 65, 512]               0\n",
            "           Linear-45              [-1, 65, 512]         262,656\n",
            "          Dropout-46              [-1, 65, 512]               0\n",
            "      FeedForward-47              [-1, 65, 512]               0\n",
            "          PreNorm-48              [-1, 65, 512]               0\n",
            "        LayerNorm-49              [-1, 65, 512]           1,024\n",
            "           Linear-50             [-1, 65, 1536]         786,432\n",
            "          Softmax-51            [-1, 8, 65, 65]               0\n",
            "           Linear-52              [-1, 65, 512]         262,656\n",
            "          Dropout-53              [-1, 65, 512]               0\n",
            "        Attention-54              [-1, 65, 512]               0\n",
            "          PreNorm-55              [-1, 65, 512]               0\n",
            "        LayerNorm-56              [-1, 65, 512]           1,024\n",
            "           Linear-57              [-1, 65, 512]         262,656\n",
            "             GELU-58              [-1, 65, 512]               0\n",
            "          Dropout-59              [-1, 65, 512]               0\n",
            "           Linear-60              [-1, 65, 512]         262,656\n",
            "          Dropout-61              [-1, 65, 512]               0\n",
            "      FeedForward-62              [-1, 65, 512]               0\n",
            "          PreNorm-63              [-1, 65, 512]               0\n",
            "        LayerNorm-64              [-1, 65, 512]           1,024\n",
            "           Linear-65             [-1, 65, 1536]         786,432\n",
            "          Softmax-66            [-1, 8, 65, 65]               0\n",
            "           Linear-67              [-1, 65, 512]         262,656\n",
            "          Dropout-68              [-1, 65, 512]               0\n",
            "        Attention-69              [-1, 65, 512]               0\n",
            "          PreNorm-70              [-1, 65, 512]               0\n",
            "        LayerNorm-71              [-1, 65, 512]           1,024\n",
            "           Linear-72              [-1, 65, 512]         262,656\n",
            "             GELU-73              [-1, 65, 512]               0\n",
            "          Dropout-74              [-1, 65, 512]               0\n",
            "           Linear-75              [-1, 65, 512]         262,656\n",
            "          Dropout-76              [-1, 65, 512]               0\n",
            "      FeedForward-77              [-1, 65, 512]               0\n",
            "          PreNorm-78              [-1, 65, 512]               0\n",
            "        LayerNorm-79              [-1, 65, 512]           1,024\n",
            "           Linear-80             [-1, 65, 1536]         786,432\n",
            "          Softmax-81            [-1, 8, 65, 65]               0\n",
            "           Linear-82              [-1, 65, 512]         262,656\n",
            "          Dropout-83              [-1, 65, 512]               0\n",
            "        Attention-84              [-1, 65, 512]               0\n",
            "          PreNorm-85              [-1, 65, 512]               0\n",
            "        LayerNorm-86              [-1, 65, 512]           1,024\n",
            "           Linear-87              [-1, 65, 512]         262,656\n",
            "             GELU-88              [-1, 65, 512]               0\n",
            "          Dropout-89              [-1, 65, 512]               0\n",
            "           Linear-90              [-1, 65, 512]         262,656\n",
            "          Dropout-91              [-1, 65, 512]               0\n",
            "      FeedForward-92              [-1, 65, 512]               0\n",
            "          PreNorm-93              [-1, 65, 512]               0\n",
            "      Transformer-94              [-1, 65, 512]               0\n",
            "         Identity-95                  [-1, 512]               0\n",
            "        LayerNorm-96                  [-1, 512]           1,024\n",
            "           Linear-97                   [-1, 10]           5,130\n",
            "================================================================\n",
            "Total params: 9,489,930\n",
            "Trainable params: 9,489,930\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 26.71\n",
            "Params size (MB): 36.20\n",
            "Estimated Total Size (MB): 62.92\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uqAyuVtnxsjK",
        "outputId": "d5df696d-e5ca-4bd5-c251-c93af2708e7a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "IMAGE_SIZE = 32\n",
        "\n",
        "NUM_CLASSES = 10\n",
        "NUM_WORKERS = 8\n",
        "BATCH_SIZE = 128\n",
        "EPOCHS = 10\n",
        "\n",
        "cifar10_mean = (0.4914, 0.4822, 0.4465)\n",
        "cifar10_std = (0.2471, 0.2435, 0.2616)\n",
        "\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.RandomResizedCrop(32, scale=(0.75, 1.0), ratio=(1.0, 1.0)),\n",
        "    transforms.RandomHorizontalFlip(p=0.5),\n",
        "    transforms.RandAugment(num_ops=1, magnitude=8),\n",
        "    transforms.ColorJitter(0.1, 0.1, 0.1),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(cifar10_mean, cifar10_std),\n",
        "    transforms.RandomErasing(p=0.25)\n",
        "])\n",
        "\n",
        "test_transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(cifar10_mean, cifar10_std)\n",
        "])\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
        "                                        download=True, transform=train_transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=BATCH_SIZE,\n",
        "                                          shuffle=True, num_workers=4)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
        "                                       download=True, transform=test_transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=64,\n",
        "                                         shuffle=False, num_workers=4)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "orP4qguJxsjL"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "\n",
        "clip_norm = True\n",
        "\n",
        "model = nn.DataParallel(model, device_ids=[0]).cuda()\n",
        "opt = optim.Adam(model.parameters(), lr=1e-2)\n",
        "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(opt, EPOCHS)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "scaler = torch.cuda.amp.GradScaler()\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    start = time.time()\n",
        "    train_loss, train_acc, n = 0, 0, 0\n",
        "    pbar = tqdm(trainloader)\n",
        "    for i, (X, y) in enumerate(trainloader):\n",
        "        model.train()\n",
        "        X, y = X.cuda(), y.cuda()\n",
        "\n",
        "        # lr = lr_schedule(epoch + (i + 1)/len(trainloader))\n",
        "        # opt.param_groups[0].update(lr=lr)\n",
        "\n",
        "        with torch.cuda.amp.autocast():\n",
        "            output = model(X)\n",
        "            loss = criterion(output, y)\n",
        "\n",
        "        scaler.scale(loss).backward()\n",
        "        if clip_norm:\n",
        "            scaler.unscale_(opt)\n",
        "            nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "        scaler.step(opt)\n",
        "        scaler.update()\n",
        "        opt.zero_grad()        \n",
        "        \n",
        "        train_loss += loss.item() * y.size(0)\n",
        "        train_acc += (output.max(1)[1] == y).sum().item()\n",
        "        n += y.size(0)\n",
        "        pbar.set_description(desc=f'Loss={train_loss :0.4f} Batch={i} Train Acc={train_acc/n :0.4f}')          \n",
        "        \n",
        "    model.eval()\n",
        "    test_acc, m = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for i, (X, y) in enumerate(testloader):\n",
        "            X, y = X.cuda(), y.cuda()\n",
        "            with torch.cuda.amp.autocast():\n",
        "                output = model(X)\n",
        "            test_acc += (output.max(1)[1] == y).sum().item()\n",
        "            m += y.size(0)\n",
        "    \n",
        "    scheduler.step(epoch-1)\n",
        "\n",
        "    print(f' Epoch: {epoch} | Train Acc: {train_acc/n:.4f}, Test Acc: {test_acc/m:.4f}, Time: {time.time() - start:.1f}, lr: {lr:.6f}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gbtap_bCxsjM"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "b8fbfcbe0e544000e4ba3d2d9974592a7ba1a2af52205db5302ae41a0c45d995"
      }
    },
    "colab": {
      "provenance": []
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}