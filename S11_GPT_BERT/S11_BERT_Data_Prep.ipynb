{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "sldf_-HJ5CIO",
        "outputId": "992717a1-a051-4a5d-8887-928736d1c197"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'i am anil & i like Ai'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "lst = ['i', 'am', 'anil', '&', 'i', 'like', 'Ai']\n",
        "sen1 = ' '.join(lst)\n",
        "sen1"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "from os.path import exists\n",
        "import numpy as np\n",
        "import random\n",
        "import math\n",
        "import re\n",
        "import copy"
      ],
      "metadata": {
        "id": "l2nXa4tH6kDx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pth = './out1.txt'\n",
        "sentences = open(pth).read().lower().split('\\n')\n",
        "\n",
        "#2) tokenize sentences (can be done during training, you can also use spacy udpipe)\n",
        "print('tokenizing sentences...')\n",
        "special_chars = ',?;.:/*!+-()[]{}\"\\'&'\n",
        "sentences = [re.sub(f'[{re.escape(special_chars)}]', ' \\g<0> ', s).split(' ') for s in sentences]\n",
        "sentences = [[w for w in s if len(w)] for s in sentences]\n",
        "len(sentences), sentences[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "92hnwXEYAPII",
        "outputId": "03832974-f2dd-443b-d46d-e9d0c08394ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tokenizing sentences...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4,\n",
              " ['what',\n",
              "  'dimensions',\n",
              "  'can',\n",
              "  'i',\n",
              "  'give',\n",
              "  'for',\n",
              "  'text',\n",
              "  'bert',\n",
              "  '?',\n",
              "  'in',\n",
              "  'this',\n",
              "  'python',\n",
              "  'tutorial',\n",
              "  ',',\n",
              "  'we',\n",
              "  'will',\n",
              "  'learn',\n",
              "  'how',\n",
              "  'to',\n",
              "  'create',\n",
              "  'a',\n",
              "  'pytorch',\n",
              "  'model',\n",
              "  'summary',\n",
              "  'in',\n",
              "  'python',\n",
              "  'and',\n",
              "  'we',\n",
              "  'will',\n",
              "  'also',\n",
              "  'cover',\n",
              "  'different',\n",
              "  'examples',\n",
              "  'related',\n",
              "  'to',\n",
              "  'the',\n",
              "  'pytorch',\n",
              "  'model',\n",
              "  'summary',\n",
              "  '.'])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "out_file = \"./out1.txt\"\n",
        "with open(out_file, 'w') as f1:\n",
        "    for item in sentences:\n",
        "        str1 = ' '.join(item)\n",
        "        str1 += \"\\n\"\n",
        "        f1.write(str1)"
      ],
      "metadata": {
        "id": "2GlXOkIlBanQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# pth = './BERT/training.txt'\n",
        "pth = './quanta.txt'\n",
        "sentences = open(pth).read().lower().split('\\n')\n",
        "len(sentences)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bQFE9ZNu53Ud",
        "outputId": "752882b8-53b5-48de-94ce-8fc99cd7aefe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "67"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_lst = []\n",
        "i = 0\n",
        "j = 0\n",
        "tot_len = 0\n",
        "new_len = 0\n",
        "for lst in sentences:\n",
        "    tot_len += len(lst)\n",
        "    sub_lst = []\n",
        "    for elem in lst:\n",
        "        sub_lst.append(elem)\n",
        "        if elem == '.':\n",
        "            new_lst.append(sub_lst)\n",
        "            sub_lst = []\n",
        "        j += 1\n",
        "    i += 1\n",
        "\n",
        "for sen in new_lst:\n",
        "    new_len += len(sen)\n",
        "\n",
        "print(f'tot_len : {tot_len} , new_len : {new_len} , old_num_sent : {len(sentences)} , new_num_sent : {len(new_lst)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n0IWTFGY60Tl",
        "outputId": "71e14c6d-9e21-4e0b-f693-362127e08de2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tot_len : 19601 , new_len : 18887 , old_num_sent : 67 , new_num_sent : 141\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "out_file = \"./out2.txt\"\n",
        "with open(out_file, 'w') as f1:\n",
        "    for lst in new_lst:\n",
        "        str1 = ''.join(lst).lstrip()\n",
        "        str1 += \"\\n\"\n",
        "        f1.write(str1)"
      ],
      "metadata": {
        "id": "Nh0AlVq0D2QE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pth = './out2.txt'\n",
        "new_sentences = open(pth).read().lower().split('\\n')\n",
        "len(new_sentences), new_sentences[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9P1egGy-OHT0",
        "outputId": "630a9904-66e3-4877-9c01-4f81d1e390e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(142,\n",
              " 'in january 2022, a small team of physicists watched breathlessly as data streamed out of googleâ€™s quantum computer, sycamore.')"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "quanta_train_file = \"./quanta_train.txt\"\n",
        "with open(quanta_train_file, 'w') as f1:\n",
        "    for _ in range(1000):\n",
        "        for lst in new_sentences:\n",
        "            str_w = ''.join(lst).lstrip()\n",
        "            str_w += \"\\n\"\n",
        "            f1.write(str_w)"
      ],
      "metadata": {
        "id": "ije53X-6Skal"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rFYtf913SqXf",
        "outputId": "bfd5685b-69ef-4298-c59f-91107a8a5d82"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp \"/content/quanta_train.txt\" \"/content/gdrive/My Drive/EVA8_S11_Course_Docs/BERT\""
      ],
      "metadata": {
        "id": "52_OWiyjVauD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KEKNqDz7V8Ou"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}